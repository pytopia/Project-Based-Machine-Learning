{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5ee8ef-f2ba-46f5-a304-2622e41cecaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img src=\"../../images/logos/ml-logo.png\" width=\"23\"/> Gradient Descent (Problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242499b2-2cac-4aad-8443-0476a0c17c9d",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following series is commonly used in gradient descent to update the model parameters?\n",
    "\n",
    "1. Taylor series\n",
    "2. Fourier series\n",
    "3. Power series\n",
    "4. Laurent series\n",
    "\n",
    "**Answer:**  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24121dce-be33-4691-9cc3-0ffa54febdb2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a57b31-cca8-4505-afc3-91170a397b39",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following formulas represents the **second-order** gradient descent method for cost function $c(w)$ ?\n",
    "\n",
    "1. $w_{t+1}=w_t-\\frac{c''(w_t)}{c'(w_t)}$\n",
    "\n",
    "2. $w_{t+1}=w_t-\\frac{c'(w_t)}{c''(w_t)}$\n",
    "\n",
    "3. $w_{t+1}=w_t-c'(w_t)$\n",
    "\n",
    "4. $w_{t+1}=w_t-c''(w_t)$\n",
    "\n",
    "**Answer:**  2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4295ad-fcfa-4cf2-ac17-135d96c04865",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd545902-3143-4ee5-a66c-1816d85e07ba",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following formulas represents the **first-order** gradient descent method for cost function $c(\\mathbf{w})$ with step-size $\\eta_t$ ?\n",
    "\n",
    "1. $\\mathbf{w}_{t+1}=\\mathbf{w}_t + \\eta_t\\Delta{c(\\mathbf{w}_t)}$\n",
    "\n",
    "1. $\\mathbf{w}_{t+1}=\\mathbf{w}_t - \\eta_t\\Delta{c(\\mathbf{w}_t)}$\n",
    "\n",
    "1. $\\mathbf{w}_{t+1}=\\mathbf{w}_t + \\eta_t\\nabla{c(\\mathbf{w}_t)}$\n",
    "\n",
    "1. $\\mathbf{w}_{t+1}=\\mathbf{w}_t - \\eta_t\\nabla{c(\\mathbf{w}_t)}$\n",
    "\n",
    "**Answer:**  4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9969ee-5c51-472e-b415-700c76de3667",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f7be8-3d0a-44ab-b107-b88f0376db7a",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following describes the effect of step-size in first-order gradient descent?\n",
    "\n",
    "1. A too-small step-size can lead to slow convergence of gradient descent\n",
    "2. A too-large step-size can cause oscillation around the minimum.\n",
    "3. An adaptive step-size likely starts larger and then slowly reduces over time as a stationary point is approached.\n",
    "4. All of the above\n",
    "\n",
    "**Answer:**  4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b99ae-00ca-4779-ba69-67350227e2a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03b4fc-171b-400e-a5a8-6a8de48c053b",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following describes **overshoot** in first-order gradient descent based on the step-size?\n",
    "\n",
    "1. Overshoot occurs when the step-size is too small, and the model parameters do not update enough.\n",
    "2. Overshoot occurs when the step-size is too large, and the model parameters update too much, causing the algorithm to diverge.\n",
    "3. Overshoot occurs when the step-size is just right, and the model parameters converge quickly to the optimal values.\n",
    "4. Overshoot occurs when the step-size is irrelevant, and the model parameters converge smoothly to the optimal values.\n",
    "\n",
    "**Answer:**  2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05c596-5250-4aff-87da-3aee83b76b04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545315b-3a25-438b-bcb9-148c73184ea7",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following can complete the following statement?  \n",
    "\"Line search is...\"\n",
    "\n",
    "1. not used to obtain adaptive step-sizes.\n",
    "2. the only method to obtain adaptive step-sizes.\n",
    "3. one of the methods to obtain adaptive step-sizes.\n",
    "4. used to obtain fixed step-sizes.\n",
    "\n",
    "**Answer:**  3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee950e1f-a80c-46ec-8f08-bc8ece05d204",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1879217-98b2-4992-a6a4-0d1483617549",
   "metadata": {},
   "source": [
    "**Question:**  \n",
    "Which of the following represents the formula of the gradient of normalized cost function for linear regression $c(\\mathbf{w})=\\frac{1}{2n} ||\\mathbf{Xw}-\\mathbf{y}||_2^{2}$ ?\n",
    "1. $\\nabla c(\\mathbf{w})=\\mathbf{X}(\\mathbf{Xw}-\\mathbf{y})$\n",
    "\n",
    "1. $\\nabla c(\\mathbf{w})=\\mathbf{X}^{T}(\\mathbf{Xw}-\\mathbf{y})$\n",
    "\n",
    "1. $\\nabla c(\\mathbf{w})=\\frac{1}{n}\\mathbf{X}(\\mathbf{Xw}-\\mathbf{y})$\n",
    "\n",
    "1. $\\nabla c(\\mathbf{w})=\\frac{1}{n}\\mathbf{X}^{T}(\\mathbf{Xw}-\\mathbf{y})$\n",
    "\n",
    "**Answer:**  4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a44b4-d4bb-4c4a-ac8a-0c354839269d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
